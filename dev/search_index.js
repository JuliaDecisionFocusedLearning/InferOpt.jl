var documenterSearchIndex = {"docs":
[{"location":"api/#API-Reference","page":"API reference","title":"API Reference","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"InferOpt","category":"page"},{"location":"api/#InferOpt","page":"API reference","title":"InferOpt","text":"InferOpt\n\nA toolbox for using combinatorial optimization algorithms within machine learning pipelines.\n\nSee our preprint https://arxiv.org/abs/2207.13513\n\n\n\n\n\n","category":"module"},{"location":"api/#Types","page":"API reference","title":"Types","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"Modules = [InferOpt]\nOrder   = [:type]","category":"page"},{"location":"api/#InferOpt.AbstractLayer","page":"API reference","title":"InferOpt.AbstractLayer","text":"AbstractLayer\n\nSupertype for all the layers defined in InferOpt.\n\nAll of these layers are callable, and differentiable with any ChainRules-compatible autodiff backend.\n\nInterface\n\n(layer::AbstractLayer)(args...; kwargs...)\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.AbstractLossLayer","page":"API reference","title":"InferOpt.AbstractLossLayer","text":"AbstractLossLayer <: AbstractLayer\n\nSupertype for all the loss layers defined in InferOpt.\n\nDepending on the precise loss, the arguments to the layer might vary\n\nInterface\n\n(layer::AbstractLossLayer)(θ; kwargs...) or\n(layer::AbstractLossLayer)(θ, θ_true; kwargs...) or\n(layer::AbstractLossLayer)(θ, y_true; kwargs...) or\n(layer::AbstractLossLayer)(θ, (; θ_true, y_true); kwargs...)\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.AbstractOptimizationLayer","page":"API reference","title":"InferOpt.AbstractOptimizationLayer","text":"AbstractOptimizationLayer <: AbstractLayer\n\nSupertype for all the optimization layers defined in InferOpt.\n\nInterface\n\n(layer::AbstractOptimizationLayer)(θ; kwargs...)\ncompute_probability_distribution(layer, θ; kwargs...) (only if the layer is probabilistic)\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.AbstractPerturbed","page":"API reference","title":"InferOpt.AbstractPerturbed","text":"AbstractPerturbed{parallel} <: AbstractOptimizationLayer\n\nDifferentiable perturbation of a black box optimizer.\n\nThe parameter parallel is a boolean value indicating if the perturbations are run in parallel. This is particularly useful if your black box optimizer running time is high.\n\nAvailable implementations:\n\nPerturbedAdditive\nPerturbedMultiplicative\nPerturbedOracle\n\nThese three subtypes share the following fields:\n\noracle: black box (optimizer)\nperturbation::P: perturbation distribution of the input θ\ngrad_logdensity::G: gradient of the log density perturbation w.r.t. input θ\nnb_samples::Int: number of perturbation samples drawn at each forward pass\nseed::Union{Nothing,Int}: seed of the perturbation.   It is reset each time the forward pass is called,   making it deterministic by always drawing the same perturbations.   If you do not want this behaviour, set this field to nothing.\nrng::AbstractRNG: random number generator using the seed.\n\nwarning: Warning\nThe perturbation field does not mean the same thing for a PerturbedOracle than for a PerturbedAdditive/PerturbedMultiplicative. See their respective docs.\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.AbstractPerturbed-Tuple{AbstractArray}","page":"API reference","title":"InferOpt.AbstractPerturbed","text":"(perturbed::AbstractPerturbed)(θ; kwargs...)\n\nForward pass. Compute the expectation of the underlying distribution.\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.AbstractRegularized","page":"API reference","title":"InferOpt.AbstractRegularized","text":"AbstractRegularized{parallel} <: AbstractOptimizationLayer\n\nConvex regularization perturbation of a black box optimizer\n\nŷ(θ) = argmax_{y ∈ C} {θᵀy - Ω(y)}\n\nInterface\n\n(regularized::AbstractRegularized)(θ; kwargs...): return ŷ(θ)\ncompute_regularization(regularized, y): return Ω(y)\n\nAvailable implementations\n\nSoftArgmax\nSparseArgmax\nRegularizedFrankWolfe\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.FenchelYoungLoss","page":"API reference","title":"InferOpt.FenchelYoungLoss","text":"FenchelYoungLoss <: AbstractLossLayer\n\nFenchel-Young loss associated with a given optimization layer.\n\nL(θ, y_true) = (Ω(y_true) - θᵀy_true) - (Ω(ŷ) - θᵀŷ)\n\nReference: https://arxiv.org/abs/1901.02324\n\nFields\n\noptimization_layer::AbstractOptimizationLayer: optimization layer that can be formulated as ŷ(θ) = argmax {θᵀy - Ω(y)} (either regularized or perturbed)\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.FenchelYoungLoss-Tuple{AbstractArray, AbstractArray}","page":"API reference","title":"InferOpt.FenchelYoungLoss","text":"(fyl::FenchelYoungLoss)(θ, y_true[; kwargs...])\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.FixedAtomsProbabilityDistribution","page":"API reference","title":"InferOpt.FixedAtomsProbabilityDistribution","text":"FixedAtomsProbabilityDistribution{A,W}\n\nEncodes a probability distribution with finite support and fixed atoms.\n\nSee compute_expectation to understand the name of this struct.\n\nFields\n\natoms::Vector{A}: elements of the support\nweights::Vector{W}: probability values for each atom (must sum to 1)\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.IdentityRelaxation","page":"API reference","title":"InferOpt.IdentityRelaxation","text":"IdentityRelaxation <: AbstractOptimizationLayer\n\nNaive relaxation of a black-box optimizer where constraints are simply forgotten.\n\nConsider (centering and) normalizing θ before applying it.\n\nFields\n\nmaximizer: underlying argmax function\n\nReference: https://arxiv.org/abs/2205.15213\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.ImitationLoss","page":"API reference","title":"InferOpt.ImitationLoss","text":"ImitationLoss <: AbstractLossLayer\n\nGeneric imitation loss of the form\n\nL(θ, t_true) = max_y {δ(y, t_true) + α θᵀ(y - y_true) - (Ω(y) - Ω(y_true))}\n\nWhen δ is zero, this is equivalent to a FenchelYoungLoss.\nWhen Ω is zero, this is equivalent to a StructuredSVMLoss.\n\nNote: by default, t_true is a named tuple with field y_true, but it can be any data structure for which the get_y_true method is implemented.\n\nFields\n\naux_loss_maximizer: function of (θ, t_true, α) that computes the argmax in the problem above\nδ: base loss function\nΩ: regularization function\nα::Float64: hyperparameter with a default value of 1.0\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.ImitationLoss-Tuple{AbstractArray, Any}","page":"API reference","title":"InferOpt.ImitationLoss","text":"(il::ImitationLoss)(θ, t_true; kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.ImitationLoss-Tuple{}","page":"API reference","title":"InferOpt.ImitationLoss","text":"ImitationLoss(; aux_loss_maximizer, δ, Ω, α=1.0)\n\nExplicit constructor with keyword arguments.\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.Interpolation","page":"API reference","title":"InferOpt.Interpolation","text":"Interpolation <: AbstractOptimizationLayer\n\nPiecewise-linear interpolation of a black-box optimizer.\n\nFields\n\nmaximizer: underlying argmax function\nλ::Float64: smoothing parameter (smaller = more faithful approximation, larger = more informative gradients)\n\nReference: https://arxiv.org/abs/1912.02175\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.PerturbedAdditive","page":"API reference","title":"InferOpt.PerturbedAdditive","text":"PerturbedAdditive{P,G,O,R,S,parallel} <: AbstractPerturbed{parallel}\n\nDifferentiable normal perturbation of a black-box maximizer: the input undergoes θ -> θ + εZ where Z ∼ N(0, I).\n\nThis OptimizationLayer is compatible with FenchelYoungLoss, if the oracle is an optimization maximizer with a linear objective.\n\nReference: https://arxiv.org/abs/2002.08676\n\nSee AbstractPerturbed for more details.\n\nSpecific field\n\nε:Float64: size of the perturbation\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.PerturbedAdditive-Union{Tuple{S}, Tuple{R}, Tuple{O}, Tuple{G}, Tuple{P}} where {P, G, O, R<:Random.AbstractRNG, S<:Union{Nothing, Int64}}","page":"API reference","title":"InferOpt.PerturbedAdditive","text":"PerturbedAdditive(oracle[; ε, nb_samples, seed, is_parallel, perturbation, grad_logdensity, rng])\n\nPerturbedAdditive constructor.\n\nArguments\n\noracle: the black-box oracle we want to differentiate through.   It should be a linear maximizer if you want to use it inside a [FenchelYoungLoss].\n\nKeyword arguments (optional)\n\nε=1.0: size of the perturbation.\nnb_samples::Int=1: number of perturbation samples drawn at each forward pass.\nperturbation=nothing: nothing by default. If you want to use a different distribution than a   Normal for the perturbation z, give it here as a distribution-like object implementing   the rand method. It should also implement logdensityof if grad_logdensity is not given.\ngrad_logdensity=nothing: gradient function of perturbation w.r.t. θ.   If set to nothing (default), it's computed using automatic differentiation.\nseed::Union{Nothing,Int}=nothing: seed of the perturbation.   It is reset each time the forward pass is called,   making it deterministic by always drawing the same perturbations.   If you do not want this behaviour, set this field to nothing.\nrng::AbstractRNG=MersenneTwister(0): random number generator using the seed.\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.PerturbedMultiplicative","page":"API reference","title":"InferOpt.PerturbedMultiplicative","text":"PerturbedMultiplicative{P,G,O,R,S,parallel} <: AbstractPerturbed{parallel}\n\nDifferentiable multiplicative perturbation of a black-box oracle: the input undergoes θ -> θ ⊙ exp[εZ - ε²/2] where Z ∼ perturbation.\n\nThis OptimizationLayer is compatible with FenchelYoungLoss, if the oracle is an optimization maximizer with a linear objective.\n\nReference: https://arxiv.org/abs/2207.13513\n\nSee AbstractPerturbed for more details.\n\nSpecific field\n\nε:Float64: size of the perturbation\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.PerturbedMultiplicative-Union{Tuple{S}, Tuple{R}, Tuple{O}, Tuple{G}, Tuple{P}} where {P, G, O, R<:Random.AbstractRNG, S<:Union{Nothing, Int64}}","page":"API reference","title":"InferOpt.PerturbedMultiplicative","text":"PerturbedMultiplicative(oracle[; ε, nb_samples, seed, is_parallel, perturbation, grad_logdensity, rng])\n\nPerturbedMultiplicative constructor.\n\nArguments\n\noracle: the black-box oracle we want to differentiate through.   It should be a linear maximizer if you want to use it inside a [FenchelYoungLoss].\n\nKeyword arguments (optional)\n\nε=1.0: size of the perturbation.\nnb_samples::Int=1: number of perturbation samples drawn at each forward pass.\nperturbation=nothing: nothing by default. If you want to use a different distribution than a   Normal for the perturbation z, give it here as a distribution-like object implementing   the rand method. It should also implement logdensityof if grad_logdensity is not given.\ngrad_logdensity=nothing: gradient function of perturbation w.r.t. θ.   If set to nothing (default), it's computed using automatic differentiation.\nseed::Union{Nothing,Int}=nothing: seed of the perturbation.   It is reset each time the forward pass is called,   making it deterministic by always drawing the same perturbations.   If you do not want this behaviour, set this field to nothing.\nrng::AbstractRNG=MersenneTwister(0): random number generator using the seed.\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.PerturbedOracle","page":"API reference","title":"InferOpt.PerturbedOracle","text":"PerturbedOracle{P,G,O,R,S,parallel} <: AbstractPerturbed{parallel}\n\nDifferentiable perturbed black-box oracle. The oracle input θ is perturbed as η ∼ perturbation(⋅|θ). PerturbedAdditive is a special case of PerturbedOracle with perturbation(θ) = MvNormal(θ, ε * I). [PerturbedMultiplicative] is also a special case of PerturbedOracle.\n\nSee AbstractPerturbed for more details about its fields.\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.PerturbedOracle-Union{Tuple{S}, Tuple{R}, Tuple{O}, Tuple{G}, Tuple{P}, Tuple{O, P}} where {P, G, O, R<:Random.AbstractRNG, S<:Union{Nothing, Int64}}","page":"API reference","title":"InferOpt.PerturbedOracle","text":"PerturbedOracle(perturbation, oracle[; grad_logdensity, rng, seed, is_parallel, nb_samples])\n\nPerturbedOracle constructor.\n\nArguments\n\noracle: the black-box oracle we want to differentiate through\nperturbation: should be a callable such that perturbation(θ) is a distribution-like   object that can be sampled with rand.   It should also implement logdensityof if grad_logdensity is not given.\n\nKeyword arguments (optional)\n\ngrad_logdensity=nothing: gradient function of perturbation w.r.t. θ.   If set to nothing (default), it's computed using automatic differentiation.\nnb_samples::Int=1: number of perturbation samples drawn at each forward pass\nseed::Union{Nothing,Int}=nothing: seed of the perturbation.   It is reset each time the forward pass is called,   making it deterministic by always drawing the same perturbations.   If you do not want this behaviour, set this field to nothing.\nrng::AbstractRNG=MersenneTwister(0): random number generator using the seed.\n\ninfo: Info\nIf you have access to the analytical expression of grad_logdensity it is recommended to give it, as it will be computationally faster.\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.Pushforward","page":"API reference","title":"InferOpt.Pushforward","text":"Pushforward <: AbstractLayer\n\nDifferentiable pushforward of a probabilistic optimization layer with an arbitrary function post-processing function.\n\nPushforward can be used for direct regret minimization (aka learning by experience) when the post-processing returns a cost.\n\nFields\n\noptimization_layer::AbstractOptimizationLayer: probabilistic optimization layer\npost_processing: callable\n\nSee also: FixedAtomsProbabilityDistribution.\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.Pushforward-Tuple{AbstractArray}","page":"API reference","title":"InferOpt.Pushforward","text":"(pushforward::Pushforward)(θ; kwargs...)\n\nOutput the expectation of pushforward.post_processing(X), where X follows the distribution defined by pushforward.optimization_layer applied to θ.\n\nUnlike compute_probability_distribution(pushforward, θ), this function is differentiable, even if pushforward.post_processing isn't.\n\nSee also: compute_expectation.\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.RegularizedFrankWolfe","page":"API reference","title":"InferOpt.RegularizedFrankWolfe","text":"RegularizedFrankWolfe <: AbstractRegularized\n\nRegularized optimization layer which relies on the Frank-Wolfe algorithm to define a probability distribution while solving\n\nŷ(θ) = argmax_{y ∈ C} {θᵀy - Ω(y)}\n\nwarning: Warning\nSince this is a conditional dependency, you need to have loaded the package DifferentiableFrankWolfe.jl before using RegularizedFrankWolfe.\n\nFields\n\nlinear_maximizer: linear maximization oracle θ -> argmax_{x ∈ C} θᵀx, implicitly defines the polytope C\nΩ: regularization function Ω(y)\nΩ_grad: gradient function of the regularization function ∇Ω(y)\nfrank_wolfe_kwargs: named tuple of keyword arguments passed to the Frank-Wolfe algorithm\n\nFrank-Wolfe parameters\n\nSome values you can tune:\n\nepsilon::Float64: precision target\nmax_iteration::Integer: max number of iterations\ntimeout::Float64: max runtime in seconds\nlazy::Bool: caching strategy\naway_steps::Bool: avoid zig-zagging\nline_search::FrankWolfe.LineSearchMethod: step size selection\nverbose::Bool: console output\n\nSee the documentation of FrankWolfe.jl for details.\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.RegularizedFrankWolfe-Tuple{AbstractArray}","page":"API reference","title":"InferOpt.RegularizedFrankWolfe","text":"(regularized::RegularizedFrankWolfe)(θ; kwargs...)\n\nApply compute_probability_distribution(regularized, θ; kwargs...) and return the expectation.\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.RegularizedFrankWolfe-Tuple{Any}","page":"API reference","title":"InferOpt.RegularizedFrankWolfe","text":"RegularizedFrankWolfe(linear_maximizer; Ω, Ω_grad, frank_wolfe_kwargs=(;))\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.SPOPlusLoss","page":"API reference","title":"InferOpt.SPOPlusLoss","text":"SPOPlusLoss <: AbstractLossLayer\n\nConvex surrogate of the Smart \"Predict-then-Optimize\" loss.\n\nFields\n\nmaximizer: linear maximizer function of the form θ -> ŷ(θ) = argmax θᵀy\nα::Float64: convexification parameter, default = 2.0\n\nReference: https://arxiv.org/abs/1710.08005\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.SPOPlusLoss-Tuple{AbstractArray, AbstractArray, AbstractArray}","page":"API reference","title":"InferOpt.SPOPlusLoss","text":"(spol::SPOPlusLoss)(θ, θ_true, y_true; kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.SPOPlusLoss-Tuple{AbstractArray, AbstractArray}","page":"API reference","title":"InferOpt.SPOPlusLoss","text":"(spol::SPOPlusLoss)(θ, θ_true; kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.SPOPlusLoss-Tuple{Any}","page":"API reference","title":"InferOpt.SPOPlusLoss","text":"SPOPlusLoss(maximizer; α=2.0)\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.SoftArgmax","page":"API reference","title":"InferOpt.SoftArgmax","text":"SoftArgmax <: Regularized\n\nSoft argmax activation function s(z) = (e^zᵢ / ∑ e^zⱼ)ᵢ.\n\nCorresponds to regularized prediction on the probability simplex with entropic penalty.\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.SparseArgmax","page":"API reference","title":"InferOpt.SparseArgmax","text":"SparseArgmax <: AbstractRegularized\n\nCompute the Euclidean projection of the vector z onto the probability simplex.\n\nCorresponds to regularized prediction on the probability simplex with square norm penalty.\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.StructuredSVMLoss","page":"API reference","title":"InferOpt.StructuredSVMLoss","text":"StructuredSVMLoss <: AbstractLossLayer\n\nLoss associated with the Structured Support Vector Machine, defined by\n\nL(θ, y_true) = max_y {δ(y, y_true) + α θᵀ(y - y_true)}\n\nReference: http://www.nowozin.net/sebastian/papers/nowozin2011structured-tutorial.pdf (Chapter 6)\n\nFields\n\naux_loss_maximizer::M: function of (θ, y_true, α) that computes the argmax in the problem above\nδ::L: base loss function\nα::Float64: hyperparameter with a default value of 1.0\n\n\n\n\n\n","category":"type"},{"location":"api/#InferOpt.StructuredSVMLoss-Tuple{AbstractArray, AbstractArray}","page":"API reference","title":"InferOpt.StructuredSVMLoss","text":"(ssvml::StructuredSVMLoss)(θ, y_true; kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.StructuredSVMLoss-Tuple{}","page":"API reference","title":"InferOpt.StructuredSVMLoss","text":"StructuredSVMLoss(; aux_loss_maximizer, δ, α=1.0)\n\n\n\n\n\n","category":"method"},{"location":"api/#Functions","page":"API reference","title":"Functions","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"Modules = [InferOpt]\nOrder   = [:function]","category":"page"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, FixedAtomsProbabilityDistribution}","page":"API reference","title":"Base.rand","text":"rand([rng,] probadist)\n\nSample from the atoms of probadist according to their weights.\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.ZeroOneImitationLoss","page":"API reference","title":"InferOpt.ZeroOneImitationLoss","text":"ZeroOneStructuredSVMLoss(α)\n\nImplementation of the ImitationLoss based on a 0-1 loss for multiclass classification with no regularization.\n\n\n\n\n\n","category":"function"},{"location":"api/#InferOpt.ZeroOneStructuredSVMLoss","page":"API reference","title":"InferOpt.ZeroOneStructuredSVMLoss","text":"ZeroOneStructuredSVMLoss\n\nImplementation of the StructuredSVMLoss based on a 0-1 loss for multiclass classification.\n\n\n\n\n\n","category":"function"},{"location":"api/#InferOpt.apply_on_atoms-Tuple{Any, FixedAtomsProbabilityDistribution}","page":"API reference","title":"InferOpt.apply_on_atoms","text":"apply_on_atoms(post_processing, probadist)\n\nCreate a new distribution by applying the function post_processing to each atom of probadist (the weights remain the same).\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.compute_expectation","page":"API reference","title":"InferOpt.compute_expectation","text":"compute_expectation(probadist[, post_processing=identity])\n\nCompute the expectation of post_processing(X) where X is a random variable distributed according to probadist.\n\nThis operation is made differentiable thanks to a custom reverse rule, even when post_processing itself is not a differentiable function.\n\nwarning: Warning\nDerivatives are computed with respect to probadist.weights only, assuming that probadist.atoms doesn't change (hence the name FixedAtomsProbabilityDistribution).\n\n\n\n\n\n","category":"function"},{"location":"api/#InferOpt.compute_probability_distribution","page":"API reference","title":"InferOpt.compute_probability_distribution","text":"compute_probability_distribution(layer, θ; kwargs...)\n\nApply a probabilistic optimization layer to an objective direction θ in order to generate a FixedAtomsProbabilityDistribution on the vertices of a polytope.\n\n\n\n\n\n","category":"function"},{"location":"api/#InferOpt.compute_probability_distribution-Tuple{InferOpt.AbstractPerturbed, AbstractArray}","page":"API reference","title":"InferOpt.compute_probability_distribution","text":"compute_probability_distribution(perturbed::AbstractPerturbed, θ; kwargs...)\n\nTurn random perturbations of θ into a distribution on polytope vertices.\n\nKeyword arguments are passed to the underlying linear maximizer.\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.compute_probability_distribution-Tuple{Pushforward, Any}","page":"API reference","title":"InferOpt.compute_probability_distribution","text":"compute_probability_distribution(pushforward, θ)\n\nOutput the distribution of pushforward.post_processing(X), where X follows the distribution defined by pushforward.optimization_layer applied to θ.\n\nThis function is not differentiable if pushforward.post_processing isn't.\n\nSee also: apply_on_atoms.\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.compute_probability_distribution_from_samples","page":"API reference","title":"InferOpt.compute_probability_distribution_from_samples","text":"compute_probability_distribution_from_samples(\n    ::AbstractPerturbed,\n    θ::AbstractArray,\n    samples::Vector{<:AbstractArray};\n    kwargs...,\n)\n\nCreate a probability distributions from samples drawn from perturbation.\n\n\n\n\n\n","category":"function"},{"location":"api/#InferOpt.compute_regularization","page":"API reference","title":"InferOpt.compute_regularization","text":"compute_regularization(regularized, y)\n\nReturn the convex penalty Ω(y) associated with an AbstractRegularized layer.\n\n\n\n\n\n","category":"function"},{"location":"api/#InferOpt.get_y_true","page":"API reference","title":"InferOpt.get_y_true","text":"get_y_true(t_true::Any)\n\nRetrieve y_true from t_true.\n\nThis method should be implemented when using a custom data structure for t_true other than a NamedTuple.\n\n\n\n\n\n","category":"function"},{"location":"api/#InferOpt.get_y_true-Tuple{NamedTuple}","page":"API reference","title":"InferOpt.get_y_true","text":"get_y_true(t_true::NamedTuple)\n\nRetrieve y_true from t_true. t_true must contain an y_true field.\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.half_square_norm-Tuple{AbstractArray}","page":"API reference","title":"InferOpt.half_square_norm","text":"half_square_norm(x)\n\nCompute the squared Euclidean norm of x and divide it by 2.\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.isproba-Tuple{Real}","page":"API reference","title":"InferOpt.isproba","text":"isproba(x)\n\nCheck whether x ∈ [0,1].\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.isprobadist-Union{Tuple{AbstractVector{R}}, Tuple{R}} where R<:Real","page":"API reference","title":"InferOpt.isprobadist","text":"isprobadist(p)\n\nCheck whether the elements of p are nonnegative and sum to 1.\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.one_hot_argmax-Union{Tuple{AbstractVector{R}}, Tuple{R}} where R<:Real","page":"API reference","title":"InferOpt.one_hot_argmax","text":"one_hot_argmax(z)\n\nOne-hot encoding of the argmax function.\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.perturbation_grad_logdensity","page":"API reference","title":"InferOpt.perturbation_grad_logdensity","text":"perturbation_grad_logdensity(\n    ::RuleConfig,\n    ::AbstractPerturbed,\n    θ::AbstractArray,\n    sample::AbstractArray,\n)\n\nCompute de gradient w.r.t to the input θ of the logdensity of the perturbed input distribution evaluated in the observed perturbation sample η.\n\n\n\n\n\n","category":"function"},{"location":"api/#InferOpt.positive_part-Tuple{Any}","page":"API reference","title":"InferOpt.positive_part","text":"positive_part(x)\n\nCompute max(x,0).\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.ranking-Tuple{AbstractVector}","page":"API reference","title":"InferOpt.ranking","text":"ranking(θ[; rev])\n\nCompute the vector r such that rᵢ is the rank of θᵢ in θ.\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.sample_perturbations","page":"API reference","title":"InferOpt.sample_perturbations","text":"sample_perturbations(perturbed::AbstractPerturbed, θ::AbstractArray)\n\nDraw nb_samples random perturbations from the perturbation distribution.\n\n\n\n\n\n","category":"function"},{"location":"api/#InferOpt.shannon_entropy-Union{Tuple{AbstractVector{R}}, Tuple{R}} where R<:Real","page":"API reference","title":"InferOpt.shannon_entropy","text":"shannon_entropy(p)\n\nCompute the Shannon entropy of a probability distribution: H(p) = -∑ pᵢlog(pᵢ).\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.simplex_projection_and_support-Tuple{AbstractVector}","page":"API reference","title":"InferOpt.simplex_projection_and_support","text":"simplex_projection_and_support(z)\n\nCompute the Euclidean projection p of z on the probability simplex (also called sparse_argmax), and the indicators s of its support.\n\nReference: https://arxiv.org/abs/1602.02068.\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.zero_one_loss-Tuple{AbstractArray, AbstractArray}","page":"API reference","title":"InferOpt.zero_one_loss","text":"zero_one_loss(y, y_true)\n\n0-1 loss for multiclass classification: δ(y, y_true) = 0 if y = y_true, and 1 otherwise.\n\n\n\n\n\n","category":"method"},{"location":"api/#InferOpt.zero_one_loss_maximizer-Union{Tuple{R}, Tuple{AbstractVector, AbstractVector{R}, Any}} where R<:Real","page":"API reference","title":"InferOpt.zero_one_loss_maximizer","text":"zero_one_loss_maximizer(y, y_true; α)\n\nFor δ = zero_one_loss, compute\n\nargmax_y {δ(y, y_true) + α θᵀ(y - y_true)}\n\n\n\n\n\n","category":"method"},{"location":"api/#Index","page":"API reference","title":"Index","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"Modules = [InferOpt]","category":"page"},{"location":"advanced_applications/#Advanced-applications","page":"Advanced applications","title":"Advanced applications","text":"","category":"section"},{"location":"advanced_applications/","page":"Advanced applications","title":"Advanced applications","text":"More advanced applications can be found in the four following satellite packages, and their associated documentations:","category":"page"},{"location":"advanced_applications/","page":"Advanced applications","title":"Advanced applications","text":"WarcraftShortestPaths.jl: computing shortest paths on Warcraft maps\nStochasticVehicleScheduling.jl: learning pipeline to solve the Stochastic Vehicle Scheduling problem\nSingleMachineScheduling.jl: learn to solve the single machine scheduling problem\nMinimumWeightTwoStageSpanningTree.jl: learn to solve the two stage minimum weight spanning tree","category":"page"},{"location":"losses/#Losses","page":"Losses","title":"Losses","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"info: Work in progress\nCome back later!","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"using AbstractTrees, InferOpt, InteractiveUtils\nAbstractTrees.children(x::Type) = subtypes(x)\nprint_tree(InferOpt.AbstractLossLayer)","category":"page"},{"location":"background/#Background","page":"Background","title":"Background","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"The goal of InferOpt.jl is to make machine learning pipelines more expressive by incorporating combinatorial optimization layers.","category":"page"},{"location":"background/#How-the-math-works","page":"Background","title":"How the math works","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"Consider the following combinatorial optimization problem:","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"    fcolon theta longmapsto arg max_v in mathcalV theta^top v","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"where mathcalV subset mathbbR^d is a finite set of feasible solutions, and theta is an objective vector. Note that any linear program (LP) or mixed integer linear program (MILP) can be formulated this way.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"Unfortunately, the optimal solution f(theta) is a piecewise constant function of theta, which means its derivative is either zero or undefined. Starting with an oracle for f, InferOpt.jl approximates it with a differentiable \"layer\", whose derivatives convey meaningful slope information. Such a layer can then be used within a machine learning pipeline, and gradient descent will succeed. InferOpt.jl also provides adequate loss functions for structured learning.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"For more details on the theoretical aspects, you can check out our paper:","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"note: Reference\nLearning with Combinatorial Optimization Layers: a Probabilistic Approach","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"For a broader perspective on the interactions between machine learning and combinatorial optimization, please refer to the following surveys:","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"note: Reference\nMachine Learning for Combinatorial Optimization: A Methodological Tour d’Horizon","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"note: Reference\nEnd-to-end Constrained Optimization Learning: A Survey","category":"page"},{"location":"background/#How-the-code-works","page":"Background","title":"How the code works","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"Since we want our package to be as generic as possible, we don't make any assumptions on the oracle used for f. That way, the best solver can be selected for each use case. We only ask the user to provide a black box function called maximizer, taking theta as argument and returning f(theta).","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"This function is then wrapped into a callable Julia struct, which can be used (for instance) within neural networks from the Flux.jl or Lux.jl library. To achieve this compatibility, we leverage Julia's automatic differentiation (AD) ecosystem, which revolves around the ChainRules.jl package.","category":"page"},{"location":"","page":"Home","title":"Home","text":"EditURL = \"https://github.com/axelparmentier/InferOpt.jl/blob/main/README.md\"","category":"page"},{"location":"#InferOpt.jl","page":"Home","title":"InferOpt.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: Stable) (Image: Dev) (Image: Build Status) (Image: Coverage) (Image: Code Style: Blue) (Image: Aqua QA)","category":"page"},{"location":"#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"InferOpt.jl is a toolbox for using combinatorial optimization algorithms within machine learning pipelines.","category":"page"},{"location":"","page":"Home","title":"Home","text":"It allows you to create differentiable layers from optimization oracles that do not have meaningful derivatives. Typical examples include mixed integer linear programs or graph algorithms.","category":"page"},{"location":"#Getting-started","page":"Home","title":"Getting started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install the stable version, open a Julia REPL and run the following command:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using Pkg; Pkg.add(\"InferOpt\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"To install the development version (recommended for now), run this command instead:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using Pkg; Pkg.add(url=\"https://github.com/axelparmentier/InferOpt.jl\")","category":"page"},{"location":"#Citing-us","page":"Home","title":"Citing us","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you use our package in your research, please cite the following paper:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Learning with Combinatorial Optimization Layers: a Probabilistic Approach - Guillaume Dalle, Léo Baty, Louis Bouvier and Axel Parmentier (2022)","category":"page"},{"location":"#Related-packages","page":"Home","title":"Related packages","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The following libraries implement similar functionalities:","category":"page"},{"location":"","page":"Home","title":"Home","text":"ImplicitDifferentiation.jl: automatic differentiation of implicit functions \nDiffOpt.jl: differentiating convex optimization programs w.r.t. program parameters\nJAXopt: hardware accelerated, batchable and differentiable optimizers in JAX","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"EditURL = \"https://github.com/axelparmentier/InferOpt.jl/blob/main/examples/tutorial.jl\"","category":"page"},{"location":"tutorial/#Basic-tutorial","page":"Basic tutorial","title":"Basic tutorial","text":"","category":"section"},{"location":"tutorial/#Context","page":"Basic tutorial","title":"Context","text":"","category":"section"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"Let us imagine that we observe the itineraries chosen by a public transport user in several different networks, and that we want to understand their decision-making process (a.k.a. recover their utility function).","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"More precisely, each point in our dataset consists in:","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"a graph G\na shortest path P from the top left to the bottom right corner","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"We don't know the true costs that were used to compute the shortest path, but we can exploit a set of features to approximate these costs. The question is: how should we combine these features?","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"We will use InferOpt.jl to learn the appropriate weights, so that we may propose relevant paths to the user in the future.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"using Flux\nusing Graphs\nusing GridGraphs\nusing InferOpt\nusing LinearAlgebra\nusing ProgressMeter\nusing Random\nusing Statistics\nusing Test\nusing UnicodePlots\n\nRandom.seed!(63);\nnothing #hide","category":"page"},{"location":"tutorial/#Grid-graphs","page":"Basic tutorial","title":"Grid graphs","text":"","category":"section"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"For the purposes of this tutorial, we consider grid graphs, as implemented in GridGraphs.jl. In such graphs, each vertex corresponds to a couple of coordinates (i j), where 1 leq i leq h and 1 leq j leq w.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"To ensure acyclicity, we only allow the user to move right, down or both. Since the cost of a move is defined as the cost of the arrival vertex, any grid graph is entirely characterized by its cost matrix theta in mathbbR^h times w.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"h, w = 50, 100\nqueen_directions = GridGraphs.QUEEN_ACYCLIC_DIRECTIONS\ng = GridGraph(rand(h, w); directions=queen_directions);\nnothing #hide","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"For convenience, GridGraphs.jl also provides custom functions to compute shortest paths efficiently. Let us see what those paths look like.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"p = path_to_matrix(g, grid_topological_sort(g, 1, nv(g)));\nspy(p)","category":"page"},{"location":"tutorial/#Dataset","page":"Basic tutorial","title":"Dataset","text":"","category":"section"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"As announced, we do not know the cost of each vertex, only a set of relevant features. Let us assume that the user combines them using a shallow neural network.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"nb_features = 5\ntrue_encoder = Chain(Dense(nb_features, 1), z -> dropdims(z; dims=1));\nnothing #hide","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"The true vertex costs computed from this encoding are then used within shortest path computations. To be consistent with the literature, we frame this problem as a linear maximization problem, which justifies the change of sign in front of theta. Note that linear_maximizer can take keyword arguments, eg. to give additional information about the instance that θ doesn't contain.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"function linear_maximizer(θ; directions)\n    g = GridGraph(-θ; directions=directions)\n    path = grid_topological_sort(g, 1, nv(g))\n    return path_to_matrix(g, path)\nend;\nnothing #hide","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"We now have everything we need to build our dataset.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"nb_instances = 30\n\nX_train = [randn(Float32, nb_features, h, w) for n in 1:nb_instances];\nθ_train = [true_encoder(x) for x in X_train];\nY_train = [linear_maximizer(θ; directions=queen_directions) for θ in θ_train];\nnothing #hide","category":"page"},{"location":"tutorial/#Learning","page":"Basic tutorial","title":"Learning","text":"","category":"section"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"We create a trainable model with the same structure as the true encoder but another set of randomly-initialized weights.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"initial_encoder = Chain(Dense(nb_features, 1), z -> dropdims(z; dims=1));\nnothing #hide","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"Here is the crucial part where InferOpt.jl intervenes: the choice of a clever loss function that enables us to","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"differentiate through the shortest path maximizer, even though it is a combinatorial operation\nevaluate the quality of our model based on the paths that it recommends","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"layer = PerturbedMultiplicative(linear_maximizer; ε=0.1, nb_samples=5);\nloss = FenchelYoungLoss(layer);\nnothing #hide","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"This probabilistic layer is just a thin wrapper around our linear_maximizer, but with a very different behavior:","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"p_layer = layer(θ_train[1]; directions=queen_directions);\nspy(p_layer)","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"Instead of choosing just one path, it spreads over several possible paths, allowing its output to change smoothly as theta varies. Thanks to this smoothing, we can now train our model with a standard gradient optimizer.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"encoder = deepcopy(initial_encoder)\nopt = Flux.Adam();\nlosses = Float64[]\nfor epoch in 1:100\n    l = 0.0\n    for (x, y) in zip(X_train, Y_train)\n        grads = gradient(Flux.params(encoder)) do\n            l += loss(encoder(x), y; directions=queen_directions)\n        end\n        Flux.update!(opt, Flux.params(encoder), grads)\n    end\n    push!(losses, l)\nend;\nnothing #hide","category":"page"},{"location":"tutorial/#Results","page":"Basic tutorial","title":"Results","text":"","category":"section"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"Since the Fenchel-Young loss is convex, it is no wonder that optimization worked like a charm.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"lineplot(losses; xlabel=\"Epoch\", ylabel=\"Loss\")","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"To assess performance, we can compare the learned weights with their true (hidden) values","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"learned_weight = encoder[1].weight / norm(encoder[1].weight)\ntrue_weight = true_encoder[1].weight / norm(true_encoder[1].weight)\nhcat(learned_weight, true_weight)","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"We are quite close to recovering the exact user weights. But in reality, it doesn't matter as much as our ability to provide accurate path predictions. Let us therefore compare our predictions with the actual paths on the training set.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"normalized_hamming(x, y) = mean(x[i] != y[i] for i in eachindex(x));\nnothing #hide","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"Y_train_pred = [linear_maximizer(encoder(x); directions=queen_directions) for x in X_train];\n\ntrain_error = mean(\n    normalized_hamming(y, y_pred) for (y, y_pred) in zip(Y_train, Y_train_pred)\n)","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"Not too bad, at least compared with our random initial encoder.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"Y_train_pred_initial = [\n    linear_maximizer(initial_encoder(x); directions=queen_directions) for x in X_train\n];\n\ntrain_error_initial = mean(\n    normalized_hamming(y, y_pred) for (y, y_pred) in zip(Y_train, Y_train_pred_initial)\n)","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"This is definitely a success. Of course in real prediction settings we should measure performance on a test set as well. This is left as an exercise to the reader.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"This page was generated using Literate.jl.","category":"page"},{"location":"optim/#Optimization","page":"Optimization","title":"Optimization","text":"","category":"section"},{"location":"optim/","page":"Optimization","title":"Optimization","text":"info: Work in progress\nCome back later!","category":"page"},{"location":"optim/","page":"Optimization","title":"Optimization","text":"using AbstractTrees, InferOpt, InteractiveUtils\nAbstractTrees.children(x::Type) = subtypes(x)\nprint_tree(InferOpt.AbstractOptimizationLayer)","category":"page"}]
}
