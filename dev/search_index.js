var documenterSearchIndex = {"docs":
[{"location":"advanced_tutorials/#Advanced-applications","page":"Advanced applications","title":"Advanced applications","text":"","category":"section"},{"location":"advanced_tutorials/","page":"Advanced applications","title":"Advanced applications","text":"More advanced applications can be found in the four following satellite packages, and their associated documentations:","category":"page"},{"location":"advanced_tutorials/","page":"Advanced applications","title":"Advanced applications","text":"WarcraftShortestPaths.jl: computing shortest paths on Warcraft maps\nStochasticVehicleScheduling.jl: learning pipeline to solve the Stochastic Vehicle Scheduling problem\nSingleMachineScheduling.jl: learn to solve the single machine scheduling problem\nMinimumWeightTwoStageSpanningTree.jl: learn to solve the two stage minimum weight spanning tree","category":"page"},{"location":"background/#Background","page":"Background","title":"Background","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"The goal of InferOpt.jl is to make machine learning pipelines more expressive by incorporating combinatorial optimization layers.","category":"page"},{"location":"background/#How-the-math-works","page":"Background","title":"How the math works","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"Consider the following combinatorial optimization problem:","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"    fcolon theta longmapsto max_v in mathcalV theta^top v","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"where mathcalV subset mathbbR^d is a finite set of feasible solutions, and theta is an objective vector. Note that any linear program (LP) or mixed integer linear program (MILP) can be formulated this way.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"Unfortunately, the optimal solution f(theta) is a piecewise constant function of theta, which means its derivative is either zero or undefined. Starting with an oracle for f, InferOpt.jl approximates it with a differentiable \"layer\", whose derivatives convey meaningful slope information. Such a layer can then be used within a machine learning pipeline, and gradient descent will succeed. InferOpt.jl also provides adequate loss functions for structured learning.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"For more details on the theoretical aspects, you can check out our paper:","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"note: Reference\nLearning with Combinatorial Optimization Layers: a Probabilistic Approach","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"For a broader perspective on the interactions between machine learning and combinatorial optimization, please refer to the following surveys:","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"note: Reference\nMachine Learning for Combinatorial Optimization: A Methodological Tour d’Horizon","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"note: Reference\nEnd-to-end Constrained Optimization Learning: A Survey","category":"page"},{"location":"background/#How-the-code-works","page":"Background","title":"How the code works","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"Since we want our package to be as generic as possible, we don't make any assumptions on the oracle used for f. That way, the best solver can be selected for each use case. We only ask the user to provide a black box function called maximizer, taking theta as argument and returning f(theta).","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"This function is then wrapped into a callable Julia struct, which can be used (for instance) within neural networks from the Flux.jl library. To achieve this compatibility, we leverage Julia's automatic differentiation (AD) ecosystem, which revolves around the ChainRules.jl package. See their documentation for more details.","category":"page"},{"location":"","page":"Home","title":"Home","text":"EditURL = \"https://github.com/axelparmentier/InferOpt.jl/blob/main/README.md\"","category":"page"},{"location":"#InferOpt.jl","page":"Home","title":"InferOpt.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: Stable) (Image: Dev) (Image: Build Status) (Image: Coverage) (Image: Code Style: Blue) (Image: Aqua QA)","category":"page"},{"location":"#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"InferOpt.jl is a toolbox for using combinatorial optimization algorithms within machine learning pipelines.","category":"page"},{"location":"","page":"Home","title":"Home","text":"It allows you to create differentiable layers from optimization oracles that do not have meaningful derivatives. Typical examples include mixed integer linear programs or graph algorithms.","category":"page"},{"location":"#Getting-started","page":"Home","title":"Getting started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install the stable version, open a Julia REPL and run the following command:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using Pkg; Pkg.add(\"InferOpt\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"To install the development version, run this command instead:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using Pkg; Pkg.add(url=\"https://github.com/axelparmentier/InferOpt.jl\")","category":"page"},{"location":"#Citing-us","page":"Home","title":"Citing us","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you use our package in your research, please cite the following paper:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Learning with Combinatorial Optimization Layers: a Probabilistic Approach - Guillaume Dalle, Léo Baty, Louis Bouvier and Axel Parmentier (2022)","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"EditURL = \"https://github.com/axelparmentier/InferOpt.jl/blob/main/test/tutorial.jl\"","category":"page"},{"location":"tutorial/#Basic-tutorial","page":"Basic tutorial","title":"Basic tutorial","text":"","category":"section"},{"location":"tutorial/#Context","page":"Basic tutorial","title":"Context","text":"","category":"section"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"Let us imagine that we observe the itineraries chosen by a public transport user in several different networks, and that we want to understand their decision-making process (a.k.a. recover their utility function).","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"More precisely, each point in our dataset consists in:","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"a graph G\na shortest path P from the top left to the bottom right corner","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"We don't know the true costs that were used to compute the shortest path, but we can exploit a set of features to approximate these costs. The question is: how should we combine these features?","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"We will use InferOpt to learn the appropriate weights, so that we may propose relevant paths to the user in the future.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"using Flux\nusing Graphs\nusing GridGraphs\nusing InferOpt\nusing LinearAlgebra\nusing ProgressMeter\nusing Random\nusing Statistics\nusing Test\nusing UnicodePlots\n\nRandom.seed!(63);\nnothing #hide","category":"page"},{"location":"tutorial/#Grid-graphs","page":"Basic tutorial","title":"Grid graphs","text":"","category":"section"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"For the purposes of this tutorial, we consider grid graphs, as implemented in GridGraphs.jl. In such graphs, each vertex corresponds to a couple of coordinates (i j), where 1 leq i leq h and 1 leq j leq w.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"To ensure acyclicity, we only allow the user to move right, down or both. Since the cost of a move is defined as the cost of the arrival vertex, any grid graph is entirely characterized by its cost matrix theta in mathbbR^h times w.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"h, w = 50, 100\ng = GridGraph(rand(h, w); directions=GridGraphs.QUEEN_ACYCLIC_DIRECTIONS);\nnothing #hide","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"For convenience, GridGraphs.jl also provides custom functions to compute shortest paths efficiently. Let us see what those paths look like.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"p = path_to_matrix(g, grid_topological_sort(g, 1, nv(g)));\nspy(p)","category":"page"},{"location":"tutorial/#Dataset","page":"Basic tutorial","title":"Dataset","text":"","category":"section"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"As announced, we do not know the cost of each vertex, only a set of relevant features. Let us assume that the user combines them using a shallow neural network.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"nb_features = 5\n\ntrue_encoder = Chain(Dense(nb_features, 1), z -> dropdims(z; dims=1));\nnothing #hide","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"The true vertex costs computed from this encoding are then used within shortest path computations. To be consistent with the literature, we frame this problem as a linear maximization problem, which justifies the change of sign in front of theta.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"function linear_maximizer(θ)\n    g = GridGraph(-θ; directions=GridGraphs.QUEEN_ACYCLIC_DIRECTIONS)\n    path = grid_topological_sort(g, 1, nv(g))\n    return path_to_matrix(g, path)\nend;\nnothing #hide","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"We now have everything we need to build our dataset.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"nb_instances = 30\n\nX_train = [randn(Float32, nb_features, h, w) for n in 1:nb_instances];\nθ_train = [true_encoder(x) for x in X_train];\nY_train = [linear_maximizer(θ) for θ in θ_train];\nnothing #hide","category":"page"},{"location":"tutorial/#Learning","page":"Basic tutorial","title":"Learning","text":"","category":"section"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"We create a trainable model with the same structure as the true encoder but another set of randomly-initialized weights.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"initial_encoder = Chain(Dense(nb_features, 1), z -> dropdims(z; dims=1));\nnothing #hide","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"Here is the crucial part where InferOpt intervenes: the choice of a clever loss function that enables us to","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"differentiate through the shortest path maximizer, even though it is a combinatorial operation\nevaluate the quality of our model based on the paths that it recommends","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"regularized_predictor = PerturbedAdditive(linear_maximizer; ε=1.0, nb_samples=5);\nloss = FenchelYoungLoss(regularized_predictor);\nnothing #hide","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"The regularized predictor is just a thin wrapper around our linear_maximizer, but with a very different behavior:","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"p_regularized = regularized_predictor(θ_train[1]);\nspy(p_regularized)","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"Instead of choosing just one path, it spreads over several possible paths, allowing its output to change smoothly as theta varies. Thanks to this smoothing, we can now train our model with a standard gradient optimizer.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"encoder = deepcopy(initial_encoder)\nopt = Flux.Adam();\nlosses = Float64[]\nfor epoch in 1:200\n    l = 0.0\n    for (x, y) in zip(X_train, Y_train)\n        grads = gradient(Flux.params(encoder)) do\n            l += loss(encoder(x), y)\n        end\n        Flux.update!(opt, Flux.params(encoder), grads)\n    end\n    push!(losses, l)\nend;\nnothing #hide","category":"page"},{"location":"tutorial/#Results","page":"Basic tutorial","title":"Results","text":"","category":"section"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"Since the Fenchel-Young loss is convex, it is no wonder that optimization worked like a charm.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"lineplot(losses; xlabel=\"Epoch\", ylabel=\"Loss\")","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"To assess performance, we can compare the learned weights with their true (hidden) values","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"learned_weight = encoder[1].weight / norm(encoder[1].weight)\ntrue_weight = true_encoder[1].weight / norm(true_encoder[1].weight)\nhcat(learned_weight, true_weight)","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"We are quite close to recovering the exact user weights. But in reality, it doesn't matter as much as our ability to provide accurate path predictions. Let us therefore compare our predictions with the actual paths on the training set.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"normalized_hamming(x, y) = mean(x[i] != y[i] for i in eachindex(x))","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"Y_train_pred = [linear_maximizer(encoder(x)) for x in X_train];\n\ntrain_error = mean(\n    normalized_hamming(y, y_pred) for (y, y_pred) in zip(Y_train, Y_train_pred)\n)","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"Not too bad, at least compared with our random initial encoder.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"Y_train_pred_initial = [linear_maximizer(initial_encoder(x)) for x in X_train];\n\ntrain_error_initial = mean(\n    normalized_hamming(y, y_pred) for (y, y_pred) in zip(Y_train, Y_train_pred_initial)\n)","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"This is definitely a success. Of course in real prediction settings we should measure performance on a test set as well. This is left as an exercise to the reader.","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"","category":"page"},{"location":"tutorial/","page":"Basic tutorial","title":"Basic tutorial","text":"This page was generated using Literate.jl.","category":"page"},{"location":"algorithms/#API-Reference","page":"Algorithms & API","title":"API Reference","text":"","category":"section"},{"location":"algorithms/#Probability-distributions","page":"Algorithms & API","title":"Probability distributions","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"Modules = [InferOpt]\nPages = [\"utils/probability_distribution.jl\", \"utils/pushforward.jl\"]","category":"page"},{"location":"algorithms/#InferOpt.FixedAtomsProbabilityDistribution","page":"Algorithms & API","title":"InferOpt.FixedAtomsProbabilityDistribution","text":"FixedAtomsProbabilityDistribution{A,W}\n\nEncodes a probability distribution with finite support and fixed atoms.\n\nSee compute_expectation to understand the name of this struct.\n\nFields\n\natoms::Vector{A}: elements of the support\nweights::Vector{W}: probability values for each atom (must sum to 1)\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#InferOpt.FixedAtomsProbabilityDistribution-Tuple{FrankWolfe.ActiveSet}","page":"Algorithms & API","title":"InferOpt.FixedAtomsProbabilityDistribution","text":"FixedAtomsProbabilityDistribution(s::FrankWolfe.ActiveSet)\n\nConstruct a distribution from the active set generated by a Frank-Wolfe algorithm.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#Base.rand-Tuple{Random.AbstractRNG, FixedAtomsProbabilityDistribution}","page":"Algorithms & API","title":"Base.rand","text":"rand([rng,] probadist)\n\nSample from the atoms of probadist according to their weights.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.apply_on_atoms-Tuple{Any, FixedAtomsProbabilityDistribution}","page":"Algorithms & API","title":"InferOpt.apply_on_atoms","text":"apply_on_atoms(post_processing, probadist)\n\nCreate a new distribution by applying the function post_processing to each atom of probadist (the weights remain the same).\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.compress_distribution!-Union{Tuple{FixedAtomsProbabilityDistribution{A, W}}, Tuple{W}, Tuple{A}} where {A, W}","page":"Algorithms & API","title":"InferOpt.compress_distribution!","text":"compress_distribution!(probadist[; atol])\n\nRemove duplicated atoms in probadist (up to a tolerance on equality).\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.compute_expectation","page":"Algorithms & API","title":"InferOpt.compute_expectation","text":"compute_expectation(probadist[, post_processing=identity])\n\nCompute the expectation of post_processing(X) where X is a random variable distributed according to probadist.\n\nThis operation is made differentiable thanks to a custom reverse rule, even when post_processing itself is not a differentiable function.\n\nwarning: Warning\nDerivatives are computed with respect to probadist.weights only, assuming that probadist.atoms doesn't change (hence the name FixedAtomsProbabilityDistribution).\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#InferOpt.compute_probability_distribution","page":"Algorithms & API","title":"InferOpt.compute_probability_distribution","text":"compute_probability_distribution(layer, θ)\n\nApply a probabilistic layer (regularized or perturbed) to an objective direction θ in order to generate a FixedAtomsProbabilityDistribution on the vertices of a polytope.\n\nThe following layer types are supported:\n\nAbstractPerturbed\nRegularizedGeneric\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#InferOpt.Pushforward","page":"Algorithms & API","title":"InferOpt.Pushforward","text":"Pushforward{L,G}\n\nDifferentiable pushforward of a probabilistic layer with an arbitrary function post_processing.\n\nPushforward can be used for direct regret minimization (aka learning by experience) when the post-processing returns a cost.\n\nFields\n\nlayer::L: anything that implements compute_probability_distribution(layer, θ; kwargs...)\npost_processing::P: callable\n\nSee also: FixedAtomsProbabilityDistribution.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#InferOpt.Pushforward-Tuple{AbstractArray{<:Real}}","page":"Algorithms & API","title":"InferOpt.Pushforward","text":"(pushforward::Pushforward)(θ)\n\nOutput the expectation of pushforward.post_processing(X), where X follows the distribution defined by pushforward.layer applied to θ.\n\nUnlike compute_probability_distribution(pushforward, θ), this function is differentiable, even if pushforward.post_processing isn't.\n\nSee also: compute_expectation.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.compute_probability_distribution-Tuple{Pushforward, Any}","page":"Algorithms & API","title":"InferOpt.compute_probability_distribution","text":"compute_probability_distribution(pushforward, θ)\n\nOutput the distribution of pushforward.post_processing(X), where X follows the distribution defined by pushforward.layer applied to θ.\n\nThis function is not differentiable if pushforward.post_processing isn't.\n\nSee also: apply_on_atoms.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#Plus-identity","page":"Algorithms & API","title":"Plus identity","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"note: Reference\nBackpropagation through Combinatorial Algorithms: Identity with Projection Works","category":"page"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"Modules = [InferOpt]\nPages = [\"plus_identity/plus_identity.jl\"]","category":"page"},{"location":"algorithms/#InferOpt.PlusIdentity","page":"Algorithms & API","title":"InferOpt.PlusIdentity","text":"PlusIdentity{F}\n\nNaive relaxation of a black-box optimizer where constraints are simply forgotten.\n\nConsider (centering and) normalizing θ before applying it.\n\nFields\n\nmaximizer::F: underlying argmax function\n\nReference: https://arxiv.org/abs/2205.15213\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#Interpolation","page":"Algorithms & API","title":"Interpolation","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"note: Reference\nDifferentiation of Blackbox Combinatorial Solvers","category":"page"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"Modules = [InferOpt]\nPages = [\"interpolation/interpolation.jl\"]","category":"page"},{"location":"algorithms/#InferOpt.Interpolation","page":"Algorithms & API","title":"InferOpt.Interpolation","text":"Interpolation{F}\n\nPiecewise-linear interpolation of a black-box optimizer.\n\nFields\n\nmaximizer::F: underlying argmax function\nλ::Float64: smoothing parameter (smaller = more faithful approximation, larger = more informative gradients)\n\nReference: https://arxiv.org/abs/1912.02175\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#Smart-\"Predict,-then-Optimize\"","page":"Algorithms & API","title":"Smart \"Predict, then Optimize\"","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"note: Reference\nSmart \"Predict, then Optimize\"","category":"page"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"Modules = [InferOpt]\nPages = [\"spo/spoplus_loss.jl\"]","category":"page"},{"location":"algorithms/#InferOpt.SPOPlusLoss","page":"Algorithms & API","title":"InferOpt.SPOPlusLoss","text":"SPOPlusLoss{F}\n\nConvex surrogate of the Smart \"Predict-then-Optimize\" loss.\n\nFields\n\nmaximizer::F: linear maximizer function of the form θ ⟼ ŷ(θ) = argmax θᵀy\nα::Float64: convexification parameter\n\nReference: https://arxiv.org/abs/1710.08005\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#Structured-Support-Vector-Machines","page":"Algorithms & API","title":"Structured Support Vector Machines","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"note: Reference\nStructured learning and prediction in computer vision, Chapter 6","category":"page"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"Modules = [InferOpt]\nPages = [\"ssvm/isbaseloss.jl\", \"ssvm/ssvm_loss.jl\", \"ssvm/zeroone_baseloss.jl\"]","category":"page"},{"location":"algorithms/#InferOpt.IsBaseLoss","page":"Algorithms & API","title":"InferOpt.IsBaseLoss","text":"IsBaseLoss{L}\n\nTrait-based interface for loss functions δ(y, y_true), which are the base of the more complex StructuredSVMLoss.\n\nFor δ::L to comply with this interface, the following methods must exist:\n\n(δ)(y, y_true)\ncompute_maximizer(δ, θ, α, y_true)\n\nAvailable implementations\n\nZeroOneBaseLoss\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#InferOpt.compute_maximizer","page":"Algorithms & API","title":"InferOpt.compute_maximizer","text":"compute_maximizer(δ, θ, α, y_true)\n\nCompute argmax_y {δ(y, y_true) + α θᵀ(y - y_true)} to deduce the gradient of a StructuredSVMLoss.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#InferOpt.StructuredSVMLoss","page":"Algorithms & API","title":"InferOpt.StructuredSVMLoss","text":"StructuredSVMLoss{L}\n\nLoss associated with the Structured Support Vector Machine.\n\nSSVM(θ, y_true) = max_y {base_loss(y, y_true) + α θᵀ(y - y_true)}\n\nFields\n\nbase_loss::L:  of the IsBaseLoss trait\nα::Float64\n\nReference: http://www.nowozin.net/sebastian/papers/nowozin2011structured-tutorial.pdf (Chapter 6)\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#InferOpt.ZeroOneBaseLoss","page":"Algorithms & API","title":"InferOpt.ZeroOneBaseLoss","text":"ZeroOneBaseLoss\n\n0-1 loss for multiclass classification: δ(y, y_true) = 0 if y = y_true, and 1 otherwise.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#Frank-Wolfe","page":"Algorithms & API","title":"Frank-Wolfe","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"note: Reference\nEfficient and Modular Implicit Differentiation","category":"page"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"note: Reference\nFrankWolfe.jl: a high-performance and flexible toolbox for Frank-Wolfe algorithms and Conditional Gradients","category":"page"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"Modules = [InferOpt]\nPages = [\"frank_wolfe/frank_wolfe_utils.jl\", \"frank_wolfe/differentiable_frank_wolfe.jl\"]","category":"page"},{"location":"algorithms/#InferOpt.DEFAULT_FRANK_WOLFE_KWARGS","page":"Algorithms & API","title":"InferOpt.DEFAULT_FRANK_WOLFE_KWARGS","text":"DEFAULT_FRANK_WOLFE_KWARGS\n\nDefault configuration for the Frank-Wolfe wrapper.\n\nParameters\n\naway_steps=true: activate away steps to avoid zig-zagging\nepsilon=1e-4: precision\nlazy=true: caching strategy\nline_search=FrankWolfe.Agnostic(): step size selection\nmax_iteration=10: number of iterations\ntimeout=1.0: maximum time in seconds\nverbose=false: console output\n\n\n\n\n\n","category":"constant"},{"location":"algorithms/#InferOpt.LMOWrapper","page":"Algorithms & API","title":"InferOpt.LMOWrapper","text":"LMOWrapper{F,K}\n\nWraps a linear maximizer as a FrankWolfe.LinearMinimizationOracle.\n\nFields\n\nmaximizer::F: black box linear maximizer\nmaximizer_kwargs::K: keyword arguments passed to the maximizer whenever it is called\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#FrankWolfe.compute_extreme_point-Tuple{LMOWrapper, Any}","page":"Algorithms & API","title":"FrankWolfe.compute_extreme_point","text":"FrankWolfe.compute_extreme_point(lmo_wrapper::LMOWrapper, direction)\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.DifferentiableFrankWolfe","page":"Algorithms & API","title":"InferOpt.DifferentiableFrankWolfe","text":"DifferentiableFrankWolfe{F,G,M,S}\n\nParameterized version of the Frank-Wolfe algorithm θ -> argmin_{x ∈ C} f(x, θ), which can be differentiated implicitly wrt θ.\n\nFields\n\nf::F: function f(x, θ) to minimize wrt x\nf_grad1::G: gradient ∇ₓf(x, θ) of f wrt x\nlmo::M: linear minimization oracle θ -> argmin_{x ∈ C} θᵀx, implicitly defines the polytope C\nlinear_solver::S: solver for linear systems of equations, used during implicit differentiation\n\nApplicable methods\n\ncompute_probability_distribution(dfw::DifferentiableFrankWolfe, θ, x0)\n(dfw::DifferentiableFrankWolfe)(θ, x0)\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#InferOpt.DifferentiableFrankWolfe-Tuple{AbstractArray{<:Real}, AbstractArray{<:Real}}","page":"Algorithms & API","title":"InferOpt.DifferentiableFrankWolfe","text":"(dfw::DifferentiableFrankWolfe)(θ, x0[; fw_kwargs=(;)])\n\nApply compute_probability_distribution(dfw, θ, x0) and return the expectation.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.compute_probability_distribution-Tuple{DifferentiableFrankWolfe, AbstractArray{<:Real}, AbstractArray{<:Real}}","page":"Algorithms & API","title":"InferOpt.compute_probability_distribution","text":"compute_probability_distribution(dfw::DifferentiableFrankWolfe, θ, x0[; fw_kwargs=(;)])\n\nCompute the optimal active set by applying the away-step Frank-Wolfe algorithm with initial point x0, then turn it into a probability distribution.\n\nThe named tuple fw_kwargs is passed as keyword arguments to FrankWolfe.away_frank_wolfe.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#Regularized-optimizers","page":"Algorithms & API","title":"Regularized optimizers","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"note: Reference\nLearning with Fenchel-Young Losses","category":"page"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"Modules = [InferOpt]\nPages = [\"regularized/isregularized.jl\", \"regularized/regularized_generic.jl\", \"regularized/regularized_utils.jl\", \"regularized/soft_argmax.jl\", \"regularized/sparse_argmax.jl\"]","category":"page"},{"location":"algorithms/#InferOpt.IsRegularized","page":"Algorithms & API","title":"InferOpt.IsRegularized","text":"IsRegularized{P}\n\nTrait-based interface for regularized prediction functions ŷ(θ) = argmax {θᵀy - Ω(y)}.\n\nFor predictor::P to comply with this interface, the following methods must exist:\n\n(predictor)(θ)\ncompute_regularization(predictor, y)\n\nAvailable implementations\n\none_hot_argmax\nsoft_argmax\nsparse_argmax\nRegularizedGeneric\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#InferOpt.compute_regularization","page":"Algorithms & API","title":"InferOpt.compute_regularization","text":"compute_regularization(predictor::P, y)\n\nCompute the convex regularization function Ω(y).\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#InferOpt.RegularizedGeneric","page":"Algorithms & API","title":"InferOpt.RegularizedGeneric","text":"RegularizedGeneric{M,RF,RG,F,G,S}\n\nDifferentiable regularized prediction function ŷ(θ) = argmax_{y ∈ C} {θᵀy - Ω(y)}.\n\nRelies on the Frank-Wolfe algorithm to minimize a concave objective on a polytope.\n\nFields\n\nmaximizer::M: linear maximization oracle θ -> argmax_{x ∈ C} θᵀx, implicitly defines the polytope C\nΩ::RF: regularization function Ω(y)\nΩ_grad::RG: gradient of the regularization function ∇Ω(y)\nf::F: objective function f(x, θ) = Ω(y) - θᵀy minimized by Frank-Wolfe (computed automatically)\nf_grad1::G: gradient of the objective function ∇ₓf(x, θ) = ∇Ω(y) - θ with respect to x (computed automatically)\nlinear_solver::S: solver for linear systems of equations, used during implicit differentiation\n\nApplicable methods\n\ncompute_probability_distribution(regularized::RegularizedGeneric, θ)\n(regularized::RegularizedGeneric)(θ)\n\nSee also: DifferentiableFrankWolfe.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#InferOpt.RegularizedGeneric-Tuple{AbstractArray{<:Real}}","page":"Algorithms & API","title":"InferOpt.RegularizedGeneric","text":"(regularized::RegularizedGeneric)(θ[; maximizer_kwargs=(;), fw_kwargs=(;)])\n\nApply compute_probability_distribution(regularized, θ) and return the expectation.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.RegularizedGeneric-Tuple{Any}","page":"Algorithms & API","title":"InferOpt.RegularizedGeneric","text":"RegularizedGeneric(maximizer[; Ω, Ω_grad, linear_solver=gmres])\n\nShorter constructor with defaults.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.compute_probability_distribution-Tuple{RegularizedGeneric, AbstractArray{<:Real}}","page":"Algorithms & API","title":"InferOpt.compute_probability_distribution","text":"compute_probability_distribution(regularized::RegularizedGeneric, θ[; maximizer_kwargs=(;), fw_kwargs=(;)])\n\nConstruct a DifferentiableFrankWolfe struct and call compute_probability_distribution on it.\n\nThe named tuple maximizer_kwargs is passed as keyword arguments to the underlying maximizer, which is wrapped inside a LMOWrapper. The named tuple fw_kwargs is passed as keyword arguments to FrankWolfe.away_frank_wolfe.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.half_square_norm-Tuple{AbstractArray{<:Real}}","page":"Algorithms & API","title":"InferOpt.half_square_norm","text":"half_square_norm(x)\n\nCompute the squared Euclidean norm of x and divide it by 2.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.isproba-Tuple{Real}","page":"Algorithms & API","title":"InferOpt.isproba","text":"isproba(x)\n\nCheck whether x ∈ [0,1].\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.isprobadist-Union{Tuple{AbstractVector{R}}, Tuple{R}} where R<:Real","page":"Algorithms & API","title":"InferOpt.isprobadist","text":"isprobadist(p)\n\nCheck whether the elements of p are nonnegative and sum to 1.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.one_hot_argmax-Union{Tuple{AbstractVector{R}}, Tuple{R}} where R<:Real","page":"Algorithms & API","title":"InferOpt.one_hot_argmax","text":"one_hot_argmax(z)\n\nOne-hot encoding of the argmax function.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.positive_part-Tuple{Any}","page":"Algorithms & API","title":"InferOpt.positive_part","text":"positive_part(x)\n\nCompute max(x,0).\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.ranking-Tuple{AbstractVector{<:Real}}","page":"Algorithms & API","title":"InferOpt.ranking","text":"ranking(θ[; rev])\n\nCompute the vector r such that rᵢ is the rank of θᵢ in θ.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.shannon_entropy-Union{Tuple{AbstractVector{R}}, Tuple{R}} where R<:Real","page":"Algorithms & API","title":"InferOpt.shannon_entropy","text":"shannon_entropy(p)\n\nCompute the Shannon entropy of a probability distribution: H(p) = -∑ pᵢlog(pᵢ).\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.soft_argmax-Tuple{AbstractVector{<:Real}}","page":"Algorithms & API","title":"InferOpt.soft_argmax","text":"soft_argmax(z)\n\nSoft argmax activation function s(z) = (e^zᵢ / ∑ e^zⱼ)ᵢ.\n\nCorresponds to regularized prediction on the probability simplex with entropic penalty.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.simplex_projection_and_support-Tuple{AbstractVector{<:Real}}","page":"Algorithms & API","title":"InferOpt.simplex_projection_and_support","text":"simplex_projection_and_support(z)\n\nCompute the Euclidean projection p of z on the probability simplex (also called sparse_argmax), and the indicators s of its support.\n\nReference: https://arxiv.org/abs/1602.02068.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.sparse_argmax-Tuple{AbstractVector{<:Real}}","page":"Algorithms & API","title":"InferOpt.sparse_argmax","text":"sparse_argmax(z)\n\nCompute the Euclidean projection of the vector z onto the probability simplex.\n\nCorresponds to regularized prediction on the probability simplex with square norm penalty.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#Perturbed-optimizers","page":"Algorithms & API","title":"Perturbed optimizers","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"note: Reference\nLearning with Differentiable Perturbed Optimizers","category":"page"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"Modules = [InferOpt]\nPages = [\"perturbed/abstract_perturbed.jl\", \"perturbed/additive.jl\", \"perturbed/multiplicative.jl\"]","category":"page"},{"location":"algorithms/#InferOpt.AbstractPerturbed","page":"Algorithms & API","title":"InferOpt.AbstractPerturbed","text":"AbstractPerturbed{B}\n\nDifferentiable perturbation of a black box optimizer. The parameter parallel is a boolean value, equal to true if the perturbations are run in parallel.\n\nApplicable functions\n\ncompute_probability_distribution(perturbed::AbstractPerturbed, θ)\n(perturbed::AbstractPerturbed)(θ)\n\nAvailable subtypes\n\nPerturbedAdditive\nPerturbedMultiplicative\n\nThese subtypes share the following fields:\n\nmaximizer: black box optimizer\nε: magnitude of the perturbation\nnb_samples::Int: number of random samples for Monte-Carlo computations\nrng::AbstractRNG: random number generator\nseed::Union{Nothing,Int}: random seed\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#InferOpt.AbstractPerturbed-Tuple{AbstractArray{<:Real}}","page":"Algorithms & API","title":"InferOpt.AbstractPerturbed","text":"(perturbed::AbstractPerturbed)(θ)\n\nApply compute_probability_distribution(perturbed, θ) and return the expectation.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.compute_probability_distribution-Tuple{InferOpt.AbstractPerturbed, AbstractArray{<:Real}}","page":"Algorithms & API","title":"InferOpt.compute_probability_distribution","text":"compute_probability_distribution(perturbed::AbstractPerturbed, θ)\n\nTurn random perturbations of θ into a distribution on polytope vertices.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.sample_perturbations-Tuple{InferOpt.AbstractPerturbed, AbstractArray{<:Real}}","page":"Algorithms & API","title":"InferOpt.sample_perturbations","text":"sample_perturbations(perturbed::AbstractPerturbed, θ)\n\nDraw random perturbations Z which will be applied to the objective direction θ.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.PerturbedAdditive","page":"Algorithms & API","title":"InferOpt.PerturbedAdditive","text":"PerturbedAdditive{F}\n\nDifferentiable normal perturbation of a black-box optimizer of type F: the input undergoes θ -> θ + εZ where Z ∼ N(0, I).\n\nSee also: AbstractPerturbed.\n\nReference: https://arxiv.org/abs/2002.08676\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#InferOpt.PerturbedAdditive-Union{Tuple{S}, Tuple{R}, Tuple{F}} where {F, R, S}","page":"Algorithms & API","title":"InferOpt.PerturbedAdditive","text":"PerturbedAdditive(maximizer[; ε=1.0, nb_samples=1])\n\nShorter constructor with defaults.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.PerturbedMultiplicative","page":"Algorithms & API","title":"InferOpt.PerturbedMultiplicative","text":"PerturbedMultiplicative{F}\n\nDifferentiable log-normal perturbation of a black-box optimizer of type F: the input undergoes θ -> θ ⊙ exp[εZ - ε²/2] where Z ∼ N(0, I).\n\nSee also: AbstractPerturbed.\n\nReference: preprint coming soon.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#InferOpt.PerturbedMultiplicative-Union{Tuple{S}, Tuple{R}, Tuple{F}} where {F, R, S}","page":"Algorithms & API","title":"InferOpt.PerturbedMultiplicative","text":"PerturbedMultiplicative(maximizer[; ε=1.0, nb_samples=1])\n\nShorter constructor with defaults.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#Fenchel-Young-losses","page":"Algorithms & API","title":"Fenchel-Young losses","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"note: Reference\nLearning with Fenchel-Young Losses","category":"page"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"Modules = [InferOpt]\nPages = [\"fenchel_young/fenchel_young.jl\", \"fenchel_young/perturbed.jl\"]","category":"page"},{"location":"algorithms/#InferOpt.FenchelYoungLoss","page":"Algorithms & API","title":"InferOpt.FenchelYoungLoss","text":"FenchelYoungLoss{P}\n\nFenchel-Young loss associated with a given regularized prediction function.\n\nFields\n\npredictor::P: prediction function of the form ŷ(θ) = argmax {θᵀy - Ω(y)}\n\nReference: https://arxiv.org/abs/1901.02324\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#Generalized-imitation-losses","page":"Algorithms & API","title":"Generalized imitation losses","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"note: Reference\nLearning with Combinatorial Optimization Layers: a Probabilistic Approach","category":"page"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"Modules = [InferOpt]\nPages = [\"imitation_loss/imitation_loss.jl\"]","category":"page"},{"location":"algorithms/#InferOpt.ImitationLoss","page":"Algorithms & API","title":"InferOpt.ImitationLoss","text":"ImitationLoss{L,R,P}\n\nGeneric imitation loss: maxy baseloss(y, ttrue) + α θᵀ(y - ytrue) - (Ω(y) - Ω(y_true))).\n\nWhen base_loss = 0, this loss is equivalent to a FenchelYoungLoss. When Ω = 0, this loss is equivalent to the StructuredSVMLoss.\n\nFields\n\nmaximizer::P: function that computes   argmaxy baseloss(y, ttrue) + α θᵀ(y - ytrue) - (Ω(y) - Ω(ytrue)), takes (θ, ytrue, kwargs...)   or (θ, t_true, kwargs...) as input\nbase_loss::L: base loss, takes (y, t_true) as input\nΩ::R: regularization, takes y as input\nα::Float64: default value of 1.0\n\nNote: by default, t_true is a named tuple with field y_true,     but can be any data structure for which the get_y_true method is implemented.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#InferOpt.ImitationLoss-Tuple{Any}","page":"Algorithms & API","title":"InferOpt.ImitationLoss","text":"ImitationLoss(maximizer[; base_loss=(y,t_true)->0.0, Ω=y->0.0, α=1.0])\n\nShorter constructor with defaults.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#InferOpt.get_y_true","page":"Algorithms & API","title":"InferOpt.get_y_true","text":"get_y_true(t_true::Any)\n\nRetrieve y_true from t_true. This method should be implemented when using a custom data structure for t_true other than a NamedTuple.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#InferOpt.get_y_true-Tuple{NamedTuple}","page":"Algorithms & API","title":"InferOpt.get_y_true","text":"get_y_true(t_true::NamedTuple)\n\nRetrieve y_true from t_true. t_true must contain an y_true field.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#Index","page":"Algorithms & API","title":"Index","text":"","category":"section"},{"location":"algorithms/","page":"Algorithms & API","title":"Algorithms & API","text":"Modules = [InferOpt]","category":"page"}]
}
